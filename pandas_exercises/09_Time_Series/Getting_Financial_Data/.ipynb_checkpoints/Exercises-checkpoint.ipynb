{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Financial Data - Pandas Datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "This time you will get data from a website.\n",
    "\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:41:51.539119Z",
     "start_time": "2021-09-26T10:41:51.076575Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas_datareader as pdr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Create your time range (start and end variables). The start date should be 01/01/2015 and the end should today (whatever your today is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:41:51.554890Z",
     "start_time": "2021-09-26T10:41:51.539119Z"
    }
   },
   "outputs": [],
   "source": [
    "#not needed step but here is it :D\n",
    "start=pd.to_datetime('2015-01-01')\n",
    "end=pd.to_datetime('today')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Get an API key for one of the APIs that are supported by Pandas Datareader, preferably for AlphaVantage.\n",
    "\n",
    "If you do not have an API key for any of the supported APIs, it is easiest to get one for [AlphaVantage](https://www.alphavantage.co/support/#api-key). (Note that the API key is shown directly after the signup. You do *not* receive it via e-mail.)\n",
    "\n",
    "(For a full list of the APIs that are supported by Pandas Datareader, [see here](https://pydata.github.io/pandas-datareader/readers/index.html). As the APIs are provided by third parties, this list may change.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Use Pandas Datarader to read the daily time series for the Apple stock (ticker symbol AAPL) between 01/01/2015 and today, assign it to df_apple and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:41:55.742332Z",
     "start_time": "2021-09-26T10:41:51.556893Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading a data from AlphaVantage and assempling it to df_apple\n",
    "df_apple = pdr.data.DataReader('AAPL',\"av-daily\", start='2015-01-01',api_key='PVNXMS90EMFOYXIW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Add a new column \"stock\" to the dataframe and add the ticker symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:41:55.757560Z",
     "start_time": "2021-09-26T10:41:55.744333Z"
    }
   },
   "outputs": [],
   "source": [
    "#making new column called stock and ticker is the value\n",
    "df_apple['stock']='AAPL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Repeat the two previous steps for a few other stocks, always creating a new dataframe: Tesla, IBM and Microsoft. (Ticker symbols TSLA, IBM and MSFT.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:42:03.235569Z",
     "start_time": "2021-09-26T10:41:55.759562Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading a data from AlphaVantage and assempling it to df_tesla\n",
    "df_tesla = pdr.data.DataReader('TSLA',\"av-daily\", start='2015-01-01',api_key='PVNXMS90EMFOYXIW')\n",
    "#making new column called stock and ticker is the value\n",
    "df_tesla['stock']='TSLA'\n",
    "#reading a data from AlphaVantage and assempling it to df_ibm\n",
    "df_ibm = pdr.data.DataReader('IBM',\"av-daily\", start='2015-01-01',api_key='PVNXMS90EMFOYXIW')\n",
    "#making new column called stock and ticker is the value\n",
    "df_ibm['stock']='IBM'\n",
    "##reading a data from AlphaVantage and assempling it to df_microsoft\n",
    "df_microsoft = pdr.data.DataReader('MSFT',\"av-daily\", start='2015-01-01',api_key='PVNXMS90EMFOYXIW')\n",
    "#making new column called stock and ticker is the value\n",
    "df_microsoft['stock']='MSFT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Combine the four separate dataFrames into one combined dataFrame df that holds the information for all four stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:42:03.251264Z",
     "start_time": "2021-09-26T10:42:03.235569Z"
    }
   },
   "outputs": [],
   "source": [
    "#combine all the data we collected to a cdf\n",
    "cdf=pd.concat([df_apple,df_ibm,df_microsoft,df_tesla])\n",
    "#converting the index to timestamp\n",
    "cdf.index=pd.to_datetime(cdf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Shift the stock column into the index (making it a multi-level index consisting of the ticker symbol and the date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:42:03.283310Z",
     "start_time": "2021-09-26T10:42:03.254259Z"
    }
   },
   "outputs": [],
   "source": [
    "#making stock and date\n",
    "cdf=cdf.groupby([cdf.stock,cdf.index]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Create a dataFrame called vol, with the volume values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:42:03.299287Z",
     "start_time": "2021-09-26T10:42:03.286250Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a data frame with volume values\n",
    "vol=pd.DataFrame(cdf['volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Aggregate the data of volume to weekly.\n",
    "Hint: Be careful to not sum data from the same week of 2015 and other years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:42:03.409076Z",
     "start_time": "2021-09-26T10:42:03.301286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL                volume\n",
      "2015-01-04   53204626\n",
      "2015-01-11  282868187\n",
      "2015-01-18  304226647\n",
      "2015-01-25  198737041\n",
      "2015-02-01  465842684\n",
      "IBM               volume\n",
      "2015-01-04   5525341\n",
      "2015-01-11  24440360\n",
      "2015-01-18  23272056\n",
      "2015-01-25  31230797\n",
      "2015-02-01  32927307\n",
      "MSFT                volume\n",
      "2015-01-04   27913852\n",
      "2015-01-11  158596624\n",
      "2015-01-18  157088136\n",
      "2015-01-25  137352632\n",
      "2015-02-01  437786778\n",
      "TSLA               volume\n",
      "2015-01-04   4764443\n",
      "2015-01-11  22622034\n",
      "2015-01-18  30799137\n",
      "2015-01-25  16215501\n",
      "2015-02-01  15720217\n"
     ]
    }
   ],
   "source": [
    "#a for loop to get the value of the first level of the index\n",
    "for i in vol.index.levels[0]:\n",
    "    #for the first leve we order the dates by week and sum the values\n",
    "    vol.loc[i].resample('W').sum()\n",
    "    #print a sample\n",
    "    print(i,vol.loc[i].resample('W').sum().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. Find all the volume traded in the year of 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T10:42:03.472180Z",
     "start_time": "2021-09-26T10:42:03.411076Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL                  volume\n",
      "2015-12-31  13064316775\n",
      "IBM                 volume\n",
      "2015-12-31  1105545521\n",
      "MSFT                 volume\n",
      "2015-12-31  9057582311\n",
      "TSLA                 volume\n",
      "2015-12-31  1086708380\n"
     ]
    }
   ],
   "source": [
    "#a for loop to get the value of the first level of the index\n",
    "for i in vol.index.levels[0]:\n",
    "    #for the first level we order the dates by years and sum the values then print year 2015\n",
    "    print(i,vol.loc[i].resample('A').sum().loc[vol.loc[i].resample('A').sum().index.year==2015])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
